{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  The participation of Facebook group members with Social network analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Student name: Chia Wei Tu                         Student ID:300289967"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "import re\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use selenium to open the browser, go to Facebook, enter the account password, and click login."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_htmltext(username, password):\n",
    "    \n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    profile.set_preference(\"dom.webnotifications.enabled\", False)     \n",
    "    profile.update_preferences()     \n",
    "    driver = webdriver.Firefox(firefox_profile=profile)    \n",
    "    driver.get(\"http://upload.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_id(\"email\").send_keys(username)\n",
    "    driver.find_element_by_id(\"pass\").send_keys(password)\n",
    "    driver.find_element_by_id(\"u_0_b\").click()\n",
    "    time.sleep(3)\n",
    "    driver.get('https://upload.facebook.com/groups/237012520046062')\n",
    "    time.sleep(3)\n",
    "       \n",
    "   #Scroll the window and click to hide the message\n",
    "    for i in range(12):\n",
    "        y = 4000 * (i + 1)\n",
    "        driver.execute_script(f\"window.scrollTo(0, {y})\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        \n",
    "    #Then let selenium open all the views of X messages, OOO has replied XX, and so on, one by one.\n",
    "    #Some buttons only appear after they are clicked for the first time, so you need to repeat two rounds. \n",
    "    def ClickForMore():\n",
    "        hrefBtns = driver.find_elements_by_tag_name('a')    \n",
    "        for btn in hrefBtns:\n",
    "            try:\n",
    "                s = btn.get_attribute('data-testid')\n",
    "            except:\n",
    "                continue\n",
    "            if s == 'UFI2CommentsPagerRenderer/pager_depth_1' or s == 'UFI2CommentsPagerRenderer/pager_depth_0':\n",
    "                try:\n",
    "                    btn.click()\n",
    "                    time.sleep(1)\n",
    "                except:\n",
    "                    continue\n",
    "                \n",
    "        ClickForMore()\n",
    "        ClickForMore()      \n",
    "\n",
    "\n",
    "        htmltext = driver.page_source\n",
    "        driver.close()\n",
    "    \n",
    "        return htmltext"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse the source code\n",
    "To obtain the source code of the website and analyze it, I first use beautifulsoup to select the area of each post and message, and then compare the crawling time and member ID with the regex string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_htmltext(htmltext, start_date, end_date):\n",
    "   \n",
    "    post_persons = []\n",
    "    comment_persons = []\n",
    "    good_urllist = []\n",
    "    ustart_date = start_date.timestamp()\n",
    "    uend_date = end_date.timestamp()\n",
    "    soup = BeautifulSoup(htmltext, 'lxml')\n",
    "    body = soup.find('body')\n",
    "    posts = body.select('div[data-pagelet=\"GroupFeed\"]')[0]\n",
    "    feed_articles = posts.select('div[role=\"feed\"]')[0].select('div[role=\"article\"]')\n",
    "    other_articles = posts.select('div[role=\"article\"]')\n",
    "    articles = feed_articles + other_articles\n",
    "    \n",
    "    for article in articles:\n",
    "        if article.has_attr('id'):\n",
    "            try:\n",
    "                post_person = re.findall('title=\"(.{2,20})\"><div class=', str(article))[0]\n",
    "            except:\n",
    "                continue\n",
    "            post_time = int(re.findall('data-utime=\"(.*?)\"', str(article))[0])        \n",
    "            if post_time >= ustart_date and post_time <= uend_date:                \n",
    "                post_persons.append(post_person)\n",
    "            try:\n",
    "                good_urllist.append(re.findall('\"(/ufi/reaction/profile/browser/\\?.*?)\"', str(article))[0])\n",
    "            except:\n",
    "                pass\n",
    "    \n",
    "        elif article.has_attr('data-testid'):            \n",
    "            comment_person = re.findall('directed_target_id.*?href=\".*?\">(.*?)</a>', str(article))[0]  \n",
    "            comment_time = int(re.findall('data-utime=\"(.*?)\"', str(article))[0])\n",
    "            if comment_time >= ustart_date and post_time <= uend_date:                    \n",
    "                comment_persons.append(comment_person)                    \n",
    "                try:\n",
    "                    good_urllist.append(re.findall('\"(/ufi/reaction/profile/browser/\\?.*?)\"', str(article))[0])\n",
    "                except:\n",
    "                    pass\n",
    "    \n",
    "    return post_persons, comment_persons, good_urllist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the emoji\n",
    "must log in to Facebook to access the symbolic links. The content of each page is very uniform and simple, so it is directly parsed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_good_urllist(username, password,urllist):\n",
    "  \n",
    "    \n",
    "    output = []\n",
    "\n",
    "    profile = webdriver.FirefoxProfile()\n",
    "    profile.set_preference(\"dom.webnotifications.enabled\", False)  # Finally, turned off webnotifications...\n",
    "    profile.update_preferences()\n",
    "    driver = webdriver.Firefox(firefox_profile=profile)\n",
    "    driver.get(\"http://upload.facebook.com\")\n",
    "    time.sleep(3)\n",
    "    driver.find_element_by_id(\"email\").send_keys(username)\n",
    "    driver.find_element_by_id(\"pass\").send_keys(password)\n",
    "    driver.find_element_by_id(\"u_0_b\").click()\n",
    "    time.sleep(3)\n",
    "\n",
    "    for url in urllist:\n",
    "        driver.get('http://upload.facebook.com/' + url)\n",
    "        htmltext = driver.page_source\n",
    "        soup = BeautifulSoup(htmltext, 'html.parser')\n",
    "        for raw_text in soup.select('li[class=\"_5i_q\"]'):\n",
    "            output += re.findall(re.compile('aria-label=\"(.*?)\" class=\"_s'),str(raw_text))            \n",
    "\n",
    "    driver.close()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Organize data and output the data to CSV File\n",
    "Convert the post_persons, comment_persons, and emoji_persons produced earlier into counts, and then package the results into excel files for output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tidy_up_data(post_persons, comment_persons, emoji_persons):\n",
    "    \n",
    "    all_persons = list(set(post_persons+comment_persons+emoji_persons))\n",
    "    post_times = []\n",
    "    comment_times = []\n",
    "    emoji_times = []\n",
    "    \n",
    "    for p in all_persons:\n",
    "        post_times.append(post_persons.count(p))\n",
    "        comment_times.append(comment_persons.count(p))\n",
    "        emoji_times.append(emoji_persons.count(p))\n",
    "    \n",
    "    return pd.DataFrame(dict(PersonID=all_persons, Posts=post_times, Comments=comment_times, Emoji=emoji_times))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == '__main__':\n",
    "    username = 'CTU89967@gmail.com'\n",
    "    password = '00000000000'\n",
    "\n",
    "    htmltext = get_htmltext(username, password)\n",
    "    post_persons, comment_persons, good_urllist = parse_htmltext(htmltext, datetime.datetime(2020,11,1), datetime.datetime(2020,12,1))\n",
    "    emoji_persons = parse_good_urllist(username, password, good_urllist)\n",
    "    df = tidy_up_data(post_persons, comment_persons, emoji_persons)\n",
    "    df.to_excel('group_activity.xlsx', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
